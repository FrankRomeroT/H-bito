{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\FRANK\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\__init__.py:62\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     ArrowDtype,\n\u001b[0;32m     65\u001b[0m     Int8Dtype,\n\u001b[0;32m     66\u001b[0m     Int16Dtype,\n\u001b[0;32m     67\u001b[0m     Int32Dtype,\n\u001b[0;32m     68\u001b[0m     Int64Dtype,\n\u001b[0;32m     69\u001b[0m     UInt8Dtype,\n\u001b[0;32m     70\u001b[0m     UInt16Dtype,\n\u001b[0;32m     71\u001b[0m     UInt32Dtype,\n\u001b[0;32m     72\u001b[0m     UInt64Dtype,\n\u001b[0;32m     73\u001b[0m     Float32Dtype,\n\u001b[0;32m     74\u001b[0m     Float64Dtype,\n\u001b[0;32m     75\u001b[0m     CategoricalDtype,\n\u001b[0;32m     76\u001b[0m     PeriodDtype,\n\u001b[0;32m     77\u001b[0m     IntervalDtype,\n\u001b[0;32m     78\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     79\u001b[0m     StringDtype,\n\u001b[0;32m     80\u001b[0m     BooleanDtype,\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     NA,\n\u001b[0;32m     83\u001b[0m     isna,\n\u001b[0;32m     84\u001b[0m     isnull,\n\u001b[0;32m     85\u001b[0m     notna,\n\u001b[0;32m     86\u001b[0m     notnull,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     Index,\n\u001b[0;32m     89\u001b[0m     CategoricalIndex,\n\u001b[0;32m     90\u001b[0m     RangeIndex,\n\u001b[0;32m     91\u001b[0m     MultiIndex,\n\u001b[0;32m     92\u001b[0m     IntervalIndex,\n\u001b[0;32m     93\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     94\u001b[0m     DatetimeIndex,\n\u001b[0;32m     95\u001b[0m     PeriodIndex,\n\u001b[0;32m     96\u001b[0m     IndexSlice,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     NaT,\n\u001b[0;32m     99\u001b[0m     Period,\n\u001b[0;32m    100\u001b[0m     period_range,\n\u001b[0;32m    101\u001b[0m     Timedelta,\n\u001b[0;32m    102\u001b[0m     timedelta_range,\n\u001b[0;32m    103\u001b[0m     Timestamp,\n\u001b[0;32m    104\u001b[0m     date_range,\n\u001b[0;32m    105\u001b[0m     bdate_range,\n\u001b[0;32m    106\u001b[0m     Interval,\n\u001b[0;32m    107\u001b[0m     interval_range,\n\u001b[0;32m    108\u001b[0m     DateOffset,\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     to_numeric,\n\u001b[0;32m    111\u001b[0m     to_datetime,\n\u001b[0;32m    112\u001b[0m     to_timedelta,\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     Flags,\n\u001b[0;32m    115\u001b[0m     Grouper,\n\u001b[0;32m    116\u001b[0m     factorize,\n\u001b[0;32m    117\u001b[0m     unique,\n\u001b[0;32m    118\u001b[0m     value_counts,\n\u001b[0;32m    119\u001b[0m     NamedAgg,\n\u001b[0;32m    120\u001b[0m     array,\n\u001b[0;32m    121\u001b[0m     Categorical,\n\u001b[0;32m    122\u001b[0m     set_eng_float_format,\n\u001b[0;32m    123\u001b[0m     Series,\n\u001b[0;32m    124\u001b[0m     DataFrame,\n\u001b[0;32m    125\u001b[0m )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32mc:\\Users\\FRANK\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\FRANK\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mmissing.pyx:40\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas fillna con ffill o bfill\n",
    "* Recomendación:\n",
    "\n",
    "**Adecuado para datos de series temporales o donde hay una lógica clara de continuidad.\n",
    "Específicamente útil cuando tienes datos ordenados cronológicamente y tiene sentido que los valores faltantes sean reemplazados por el valor más cercano en el tiempo (anterior o siguiente).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  stock_price  stock_price_ffill  stock_price_bfill\n",
      "0 2023-01-01        100.0              100.0              100.0\n",
      "1 2023-01-02          NaN              100.0              102.0\n",
      "2 2023-01-03        102.0              102.0              102.0\n",
      "3 2023-01-04          NaN              102.0              104.0\n",
      "4 2023-01-05        104.0              104.0              104.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FRANK\\AppData\\Local\\Temp\\ipykernel_20276\\1307855412.py:12: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['stock_price_ffill'] = df['stock_price'].fillna(method='ffill')\n",
      "C:\\Users\\FRANK\\AppData\\Local\\Temp\\ipykernel_20276\\1307855412.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['stock_price_bfill'] = df['stock_price'].fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Crear un DataFrame con datos de series temporales (precios de acciones)\n",
    "data = {\n",
    "    'date': pd.date_range(start='2023-01-01', periods=5, freq='D'),\n",
    "    'stock_price': [100, np.nan, 102, np.nan, 104]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Usar ffill (forward fill) para rellenar valores nulos con el valor anterior\n",
    "df['stock_price_ffill'] = df['stock_price'].fillna(method='ffill')\n",
    "\n",
    "# Usar bfill (backward fill) para rellenar valores nulos con el valor siguiente\n",
    "df['stock_price_bfill'] = df['stock_price'].fillna(method='bfill')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logistica \n",
    "* Binaria: Dos categorías (Sí/No, Gana/Pierde).\n",
    "* Multinomial: Más de dos categorías sin orden (colores, marcas)\n",
    "* Ordinal: Categorías con orden (bajo, medio, alto; clase baja, clase media, clase alta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn KNNImputer\n",
    "* Recomendación:\n",
    "- Adecuado para datos multidimensionales donde se desea considerar la similitud entre muestras.\n",
    "Especialmente útil cuando tienes un conjunto de datos con múltiples características (atributos) y deseas usar la similitud entre estas características para imputar los valores faltantes.\n",
    "\n",
    "- Se debe usar con las demás columnas para que tenga coherencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Crear una instancia del KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "# Imputar los valores nulos\n",
    "df2[['historical_default',\n",
    "      'customer_age',\n",
    "      'customer_income',\n",
    "       'term_years',\n",
    "       'cred_hist_length',\n",
    "       'Current_loan_status']] = imputer.fit_transform(df2[['historical_default',\n",
    "                                                            'customer_age',\n",
    "                                                            'customer_income',\n",
    "                                                            'term_years',\n",
    "                                                            'cred_hist_length',\n",
    "                                                            'Current_loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id  customer_age  customer_income home_ownership  \\\n",
      "0            1            22            59000           RENT   \n",
      "1            2            21             9600            OWN   \n",
      "2            3            25             9600       MORTGAGE   \n",
      "3            4            23            65500           RENT   \n",
      "4            5            24            54400           RENT   \n",
      "\n",
      "   employment_duration loan_intent loan_grade   loan_amnt  loan_int_rate  \\\n",
      "0                  123    PERSONAL          C  £35,000.00          16.02   \n",
      "1                    5   EDUCATION          A   £1,000.00          11.14   \n",
      "2                    1     MEDICAL          B   £5,500.00          12.87   \n",
      "3                    4     MEDICAL          B  £35,000.00          15.23   \n",
      "4                    8     MEDICAL          B  £35,000.00          14.27   \n",
      "\n",
      "   term_years  historical_default  cred_hist_length Current_loan_status  \n",
      "0          10                   1                 3             DEFAULT  \n",
      "1           1                   0                 2          NO DEFAULT  \n",
      "2           5                   0                 3             DEFAULT  \n",
      "3          10                   0                 2             DEFAULT  \n",
      "4          10                   1                 4             DEFAULT  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Crear un DataFrame con datos multidimensionales (características de clientes)\n",
    "\n",
    "data = {\n",
    "    'customer_id': [1, 2, 3, 4, 5],\n",
    "    'customer_age': [22, 21, 25, 23, 24],\n",
    "    'customer_income': [59000, 9600, 9600, 65500, 54400],\n",
    "    'home_ownership': ['RENT', 'OWN', 'MORTGAGE', 'RENT', 'RENT'],\n",
    "    'employment_duration': [123, 5, 1, 4, 8],\n",
    "    'loan_intent': ['PERSONAL', 'EDUCATION', 'MEDICAL', 'MEDICAL', 'MEDICAL'],\n",
    "    'loan_grade': ['C', 'A', 'B', 'B', 'B'],\n",
    "    'loan_amnt': ['£35,000.00', '£1,000.00', '£5,500.00', '£35,000.00', '£35,000.00'],\n",
    "    'loan_int_rate': [16.02, 11.14, 12.87, 15.23, 14.27],\n",
    "    'term_years': [10, 1, 5, 10, 10],\n",
    "    'historical_default': ['Y', None, 'N', 'N', 'Y'],\n",
    "    'cred_hist_length': [3, 2, 3, 2, 4],\n",
    "    'Current_loan_status': ['DEFAULT', 'NO DEFAULT', 'DEFAULT', 'DEFAULT', 'DEFAULT']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convertir 'Y' y 'N' a 1 y 0\n",
    "def convert_bin(value):\n",
    "    if value == 'Y':\n",
    "        return 1\n",
    "    elif value == 'N':\n",
    "        return 0\n",
    "    return value\n",
    "\n",
    "df['historical_default'] = df['historical_default'].apply(convert_bin)\n",
    "\n",
    "# Crear una instancia del KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "# Imputar los valores nulos\n",
    "df[['historical_default']] = imputer.fit_transform(df[['historical_default']])\n",
    "\n",
    "# Asegurarse de que los valores imputados son enteros (0 o 1)\n",
    "df['historical_default'] = df['historical_default'].round().astype(int)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# df2 = df2.sort_values(by='customer_id').reset_index(drop=True) # ordenar el dataframe\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_id\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m5\u001b[39m],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_age\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m24\u001b[39m],\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_income\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m59000\u001b[39m, \u001b[38;5;241m9600\u001b[39m, \u001b[38;5;241m9600\u001b[39m, \u001b[38;5;241m65500\u001b[39m, \u001b[38;5;241m54400\u001b[39m]\n\u001b[0;32m      9\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\FRANK\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\__init__.py:62\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     ArrowDtype,\n\u001b[0;32m     65\u001b[0m     Int8Dtype,\n\u001b[0;32m     66\u001b[0m     Int16Dtype,\n\u001b[0;32m     67\u001b[0m     Int32Dtype,\n\u001b[0;32m     68\u001b[0m     Int64Dtype,\n\u001b[0;32m     69\u001b[0m     UInt8Dtype,\n\u001b[0;32m     70\u001b[0m     UInt16Dtype,\n\u001b[0;32m     71\u001b[0m     UInt32Dtype,\n\u001b[0;32m     72\u001b[0m     UInt64Dtype,\n\u001b[0;32m     73\u001b[0m     Float32Dtype,\n\u001b[0;32m     74\u001b[0m     Float64Dtype,\n\u001b[0;32m     75\u001b[0m     CategoricalDtype,\n\u001b[0;32m     76\u001b[0m     PeriodDtype,\n\u001b[0;32m     77\u001b[0m     IntervalDtype,\n\u001b[0;32m     78\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     79\u001b[0m     StringDtype,\n\u001b[0;32m     80\u001b[0m     BooleanDtype,\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     NA,\n\u001b[0;32m     83\u001b[0m     isna,\n\u001b[0;32m     84\u001b[0m     isnull,\n\u001b[0;32m     85\u001b[0m     notna,\n\u001b[0;32m     86\u001b[0m     notnull,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     Index,\n\u001b[0;32m     89\u001b[0m     CategoricalIndex,\n\u001b[0;32m     90\u001b[0m     RangeIndex,\n\u001b[0;32m     91\u001b[0m     MultiIndex,\n\u001b[0;32m     92\u001b[0m     IntervalIndex,\n\u001b[0;32m     93\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     94\u001b[0m     DatetimeIndex,\n\u001b[0;32m     95\u001b[0m     PeriodIndex,\n\u001b[0;32m     96\u001b[0m     IndexSlice,\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     NaT,\n\u001b[0;32m     99\u001b[0m     Period,\n\u001b[0;32m    100\u001b[0m     period_range,\n\u001b[0;32m    101\u001b[0m     Timedelta,\n\u001b[0;32m    102\u001b[0m     timedelta_range,\n\u001b[0;32m    103\u001b[0m     Timestamp,\n\u001b[0;32m    104\u001b[0m     date_range,\n\u001b[0;32m    105\u001b[0m     bdate_range,\n\u001b[0;32m    106\u001b[0m     Interval,\n\u001b[0;32m    107\u001b[0m     interval_range,\n\u001b[0;32m    108\u001b[0m     DateOffset,\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     to_numeric,\n\u001b[0;32m    111\u001b[0m     to_datetime,\n\u001b[0;32m    112\u001b[0m     to_timedelta,\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     Flags,\n\u001b[0;32m    115\u001b[0m     Grouper,\n\u001b[0;32m    116\u001b[0m     factorize,\n\u001b[0;32m    117\u001b[0m     unique,\n\u001b[0;32m    118\u001b[0m     value_counts,\n\u001b[0;32m    119\u001b[0m     NamedAgg,\n\u001b[0;32m    120\u001b[0m     array,\n\u001b[0;32m    121\u001b[0m     Categorical,\n\u001b[0;32m    122\u001b[0m     set_eng_float_format,\n\u001b[0;32m    123\u001b[0m     Series,\n\u001b[0;32m    124\u001b[0m     DataFrame,\n\u001b[0;32m    125\u001b[0m )\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32mc:\\Users\\FRANK\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\FRANK\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mhashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mmissing.pyx:40\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute '_pandas_datetime_CAPI' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd # type: ignore\n",
    "\n",
    "# df2 = df2.sort_values(by='customer_id').reset_index(drop=True) # ordenar el dataframe\n",
    "\n",
    "data = {\n",
    "    'customer_id': [1, 2, 3, None, 5],\n",
    "    'customer_age': [22, 21, 25, 23, 24],\n",
    "    'customer_income': [59000, 9600, 9600, 65500, 54400]\n",
    "}\n",
    "df2 = pd.DataFrame(data)\n",
    "\n",
    "print(\"Antes de reasignar IDs:\")\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de reasignar IDs:\n",
      "   customer_id  customer_age  customer_income\n",
      "0            1            22            59000\n",
      "1            2            21             9600\n",
      "2            3            25             9600\n",
      "3            4            23            65500\n",
      "4            5            24            54400\n"
     ]
    }
   ],
   "source": [
    "# Asignar nuevos IDs secuenciales a la columna customer_id\n",
    "df2['customer_id'] = range(1, len(df2) + 1)\n",
    "\n",
    "print(\"Después de reasignar IDs:\")\n",
    "print(df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['penal_1','penal_2']] = df2[['penal_1','penal_2']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_1_2['resul1'] = merged_1_2['resul1'].astype(float)\n",
    "merged_1_2['result2'] = merged_1_2['result2'].astype(float)\n",
    "merged_1_2['penal_1'] = merged_1_2['penal_1'].astype(float)\n",
    "merged_1_2['penal_2'] = merged_1_2['penal_2'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['resul1', 'result2', 'penal_1', 'penal_2']\n",
    "\n",
    "# Convertir las columnas especificadas a float\n",
    "for column in columns_to_convert: # bucle\n",
    "    merged_1_2[column] = merged_1_2[column].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La interpolación es bueno cuando hay valores secuenciales y continuos, sin embargo no es recomendable usarlo en valores que son binarios porque puede obtener valores de 0,333 | 0,555555 | 0,88888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos Continuos:\n",
    "\n",
    "La interpolación funciona mejor con datos continuos. Los datos categóricos no son adecuados para la interpolación.\n",
    "Tendencias y Patrones:\n",
    "\n",
    "La interpolación es más precisa cuando hay una tendencia o patrón claro en los datos.\n",
    "Número de Columnas:\n",
    "\n",
    "Puedes aplicar interpolación a múltiples columnas. Sin embargo, debes asegurarte de que las columnas tengan alguna relación o patrón similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m data_with_outliers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m3333\u001b[39m, \u001b[38;5;241m833333\u001b[39m, \u001b[38;5;241m9999\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m123131\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Crear un DataFrame con estos datos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df_outliers \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(data_with_outliers, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Interpolar los valores nulos\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df_outliers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues_interpolated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_outliers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39minterpolate()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Datos con valores atípicos y algunos valores nulos\n",
    "data_with_outliers = [1, 2, 3, None, 5, 6, None, 3333, 833333, 9999, None, 10, 123131]\n",
    "\n",
    "# Crear un DataFrame con estos datos\n",
    "df_outliers = pd.DataFrame(data_with_outliers, columns=['values'])\n",
    "\n",
    "# Interpolar los valores nulos\n",
    "df_outliers['values_interpolated'] = df_outliers['values'].interpolate()\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "df_outliers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2364345305.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[19], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    values  values_imputed\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "      values  values_imputed\n",
    "0        1.0             1.0\n",
    "1        2.0             2.0\n",
    "2        3.0             3.0\n",
    "3        NaN         96982.3\n",
    "4        5.0             5.0\n",
    "5        6.0             6.0\n",
    "6        NaN         96982.3\n",
    "7     3333.0          3333.0\n",
    "8   833333.0        833333.0\n",
    "9     9999.0          9999.0\n",
    "10       NaN         96982.3\n",
    "11      10.0            10.0\n",
    "12  123131.0        123131.0\n",
    "\n",
    "# Observaciones\n",
    "# La interpolación entre valores enteros normales (1, 2, 3, 5, 6) ha rellenado el valor nulo con un valor entero (4).\n",
    "# La interpolación de un valor nulo entre 6 y 3333 ha resultado en un valor decimal (1669.5), lo cual es esperable debido a la gran diferencia entre estos valores.\n",
    "# Similarmente, la interpolación entre 9999 y 10 ha resultado en un valor decimal (5004.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en variables\n",
    "enc_column = ['US-Mexico border crossing','Sahara Desert crossing',\n",
    "              'Central Mediterranean','Western Mediterranean',\n",
    "              'Afghanistan to Iran','Eastern Mediterranean',\n",
    "              'Western Africa / Atlantic route to the Canary Islands','Western Balkans',\n",
    "              'English Channel to the UK','Syria to Turkey',\n",
    "              'Turkey-Europe land route','Horn of Africa to Yemen crossing',\n",
    "              'Darien Gap','Iran to Turkey',\n",
    "              'Italy to France','Dominican Republic to Puerto Rico',\n",
    "              'Belarus-EU border','Cuba to US',\n",
    "              'Haiti to Dominican Republic','Comoros to Mayotte',\n",
    "              'Venezuela to Caribbean','DRC to Uganda']\n",
    "categoria_column = df2[enc_column]\n",
    "\n",
    "# Columnas numericas\n",
    "enc_data = df2.drop(columns=enc_column)\n",
    "\n",
    "# Encoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_data = encoder.fit_transform(categoria_column)\n",
    "\n",
    "# Convertir en dataframe\n",
    "encoded_columns = encoder.get_feature_names_out(enc_column)\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoded_columns)\n",
    "\n",
    "df2 = pd.concat([enc_data.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Migrantion route' in df2.columns:\n",
    "    # Seleccionar la columna que se va a codificar\n",
    "    categoria_column = df2[['Migrantion route']]\n",
    "\n",
    "    # Columnas numéricas\n",
    "    enc_data = df2.drop(columns=['Migrantion route'])\n",
    "\n",
    "    # Encoder\n",
    "    encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "    encoded_data = encoder.fit_transform(categoria_column)\n",
    "\n",
    "    # Convertir en DataFrame\n",
    "    encoded_columns = encoder.get_feature_names_out(['Migrantion route'])\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=encoded_columns)\n",
    "\n",
    "    # Concatenar los datos codificados con los datos numéricos\n",
    "    df2 = pd.concat([enc_data.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remplazar : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Crear un diccionario que mapea cada categoría en 'Information Source' a un número único\n",
    "source_quality_dicc = {category: idx for idx, category in enumerate(df2['Information Source'].unique(), 1)}\n",
    "\n",
    "df2['Information Source'] = df2['Information Source'].replace(source_quality_dicc)\n",
    "df2['Information Source'].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estadística, la correlación mide la fuerza y la dirección de una relación lineal entre dos variables. Aquí hay algunas pautas generales para interpretar el coeficiente de correlación de Pearson (\n",
    "𝑟\n",
    "r):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r=0: No hay correlación.\n",
    "0\n",
    "<\n",
    "∣\n",
    "𝑟\n",
    "∣\n",
    "<\n",
    "0.3\n",
    "0<∣r∣<0.3: Correlación débil.\n",
    "0.3\n",
    "≤\n",
    "∣\n",
    "𝑟\n",
    "∣\n",
    "<\n",
    "0.5\n",
    "0.3≤∣r∣<0.5: Correlación moderada.\n",
    "0.5\n",
    "≤\n",
    "∣\n",
    "𝑟\n",
    "∣\n",
    "<\n",
    "0.7\n",
    "0.5≤∣r∣<0.7: Correlación alta.\n",
    "0.7\n",
    "≤\n",
    "∣\n",
    "𝑟\n",
    "∣\n",
    "<\n",
    "1.0\n",
    "0.7≤∣r∣<1.0: Correlación muy alta.\n",
    "𝑟\n",
    "=\n",
    "1\n",
    "r=1 o \n",
    "𝑟\n",
    "=\n",
    "−\n",
    "1\n",
    "r=−1: Correlación perfecta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
